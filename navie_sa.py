# -*- coding: utf-8 -*-
"""Navie_SA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sCdv7Ey-z5erfvl_p3xmzP5VntT0v72A
"""

cd /content/drive/MyDrive/Tutorial2

#from collections import counter
import nltk
nltk.download('stopwords')
from os import listdir
from collections import Counter
from nltk.corpus import stopwords
import string
import re
import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten,Embedding
from keras.layers import MaxPooling1D , Conv1D
from keras.utils import plot_model
from keras.utils import pad_sequences
from keras import callbacks
import matplotlib.pyplot as plt
import math
from collections import defaultdict

#Removes noise(stopwords) and puncuation marks from data
def process_data(reviews):
    stop_words = set(stopwords.words('english'))
    processed_reviews = []

    for review in reviews:
        # Remove punctuation
        review = re.sub(r'[^\w\s]', '', review)
        # Lowercase
        review = review.lower()
        # Remove stopwords
        words = review.split()
        filtered_words = [word for word in words if word not in stop_words]
        processed_reviews.append(' '.join(filtered_words))

    return processed_reviews

# Define sample reviews
sample_reviews = [
    "This is a sample review with punctuation! And stopwords like the, is, and so on.",
    "Another example review without punctuation and stopwords."
]
review = ["This is a great movie !"]
# Process the sample reviews
processed_sample_reviews = process_data(sample_reviews)
processed_sample_reviews2 = process_data(review)
# Print processed reviews
for i, review in enumerate(processed_sample_reviews, 1):
    print(f"Processed Review {i}: {review}")
print(processed_sample_reviews2)

def count_reviews(reviews, labels):
    word_count = {}
    clean_reviews = process_data(reviews)

    for review, label in zip(clean_reviews, labels):
        words = review.split()
        for word in words:
            key = (word, label)
            if key in word_count:
                word_count[key] += 1
            else:
                word_count[key] = 1

    return word_count

# Test the count_reviews method with sample movie reviews
sample_reviews = [ "I am rather excited.", "You are rather happy."]
labels = [1,1]
word_count_dict = count_reviews(sample_reviews,labels)

print("Word Count Dictionary:")
print(word_count_dict)

def train_naiveBayes(word_count, labels):
    n_docs = len(labels)
    n_pos = sum(labels)
    n_neg = n_docs - n_pos

    # Prior probabilities
    p_pos = n_pos / n_docs
    p_neg = n_neg / n_docs

    logprior = math.log(p_pos) - math.log(p_neg)

    # Count total words in positive and negative reviews
    n_pos_words = sum([count for (word, label), count in word_count.items() if label == 1])
    n_neg_words = sum([count for (word, label), count in word_count.items() if label == 0])

    # Vocabulary size
    vocab = set([word for word, label in word_count.keys()])
    V = len(vocab)

    loglikelihood = {}

    for word in vocab:
        freq_pos = word_count.get((word, 1), 0)
        freq_neg = word_count.get((word, 0), 0)

        p_word_pos = (freq_pos + 1) / (n_pos_words + V)
        p_word_neg = (freq_neg + 1) / (n_neg_words + V)

        loglikelihood[word] = math.log(p_word_pos) - math.log(p_word_neg)

    return logprior, loglikelihood

def predict_naiveBayes(review, logprior, loglikelihood):
    words = review.split()
    total = logprior

    for word in words:
        if word in loglikelihood:
            total += loglikelihood[word]

    return total

def test_naiveBayes(test_reviews, test_labels, logprior, loglikelihood):
    correct = 0

    for review, label in zip(test_reviews, test_labels):
        processed_review = process_data([review])[0]
        prediction = predict_naiveBayes(processed_review, logprior, loglikelihood)

        predicted_label = 1 if prediction > 0 else 0
        if predicted_label == label:
            correct += 1

    accuracy = correct / len(test_reviews)
    return accuracy

def error_analysis(test_reviews, test_labels, logprior, loglikelihood):
    with open('error_analysis.txt', 'w') as f:
        f.write("Truth\tPredicted\tReview\n")
        for review, label in zip(test_reviews, test_labels):
            processed_review = process_data([review])[0]
            prediction = predict_naiveBayes(processed_review, logprior, loglikelihood)

            predicted_label = 1 if prediction > 0 else 0
            f.write(f"{label}\t{predicted_label}\t{review}\n")

import os
import random

# Define the directory paths for positive and negative reviews
positive_reviews_dir = '/content/drive/MyDrive/Tutorial2/pos'
negative_reviews_dir = '/content/drive/MyDrive/Tutorial2/neg'

# Function to read reviews from files in a directory
def read_reviews_from_dir(directory):
    reviews = []
    for filename in os.listdir(directory):
        with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:
            review = file.read().strip()
            reviews.append(review)
    return reviews

# Read positive and negative reviews from directories
positive_reviews = read_reviews_from_dir(positive_reviews_dir)
negative_reviews = read_reviews_from_dir(negative_reviews_dir)

# Assign labels
positive_labels = [1] * len(positive_reviews)
negative_labels = [0] * len(negative_reviews)

# Combine positive and negative reviews and labels
all_reviews = positive_reviews + negative_reviews
all_labels = positive_labels + negative_labels

# Calculate the total number of sentences
total_sentences = len(all_reviews)

# Determine the number of sentences for training (80%) and testing (20%)
train_size = int(0.8 * total_sentences)
test_size = total_sentences - train_size

# Create indices for  shuffling to randomly distribute data between
#the training and test data sets to prevent bais during training and testing
indices = list(range(total_sentences))
random.shuffle(indices)

# Split the indices into training and testing indices
train_indices = indices[:train_size]
test_indices = indices[train_size:]

# Extract sentences and labels for training and testing
train_reviews = [all_reviews[i] for i in train_indices]
train_labels = [all_labels[i] for i in train_indices]
test_reviews = [all_reviews[i] for i in test_indices]
test_labels = [all_labels[i] for i in test_indices]

# Process training data
processed_train_reviews = process_data(train_reviews)

# Count word frequencies
word_count = count_reviews(processed_train_reviews, train_labels)

# Train the model
logprior, loglikelihood = train_naiveBayes(word_count, train_labels)

# Test the model
accuracy = test_naiveBayes(test_reviews, test_labels, logprior, loglikelihood)
print(f'Naive Bayes accuracy = {accuracy:.4f}')

# Perform error analysis
error_analysis(test_reviews, test_labels, logprior, loglikelihood)

# Function to read reviews from a text file
def read_reviews_from_file(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        reviews = file.readlines()
    return [review.strip() for review in reviews]

# Read Lion King movie reviews from the text file
lion_king_reviews_path = '/content/drive/MyDrive/Tutorial2/LionKing_MovieReviews (1).txt'
lion_king_reviews = read_reviews_from_file(lion_king_reviews_path)

# Predict sentiments for Lion King movie reviews and write to output file
with open('LionKing_Output.txt', 'w', encoding='utf-8') as output_file:
    for review in lion_king_reviews:
        # Clean and preprocess the review
        processed_review = process_data([review])[0]

        # Predict sentiment
        prediction = predict_naiveBayes(processed_review, logprior, loglikelihood)
        predicted_sentiment = "Positive" if prediction > 0 else "Negative"

        # Write review and sentiment to output file
        output_file.write(f"Review: {review}\nPredicted Sentiment: {predicted_sentiment}\n\n")